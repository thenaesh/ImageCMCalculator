\documentclass[]{article}

\usepackage{amsfonts}

%opening
\title{Computing the CM of an Image in $\Theta(n^2)$}
\author{Thenaesh Elango (A0124772E)}

\begin{document}
	
	
	\maketitle
	
	\section{Introduction}
		\paragraph{}
		We present an algorithm to compute the center of mass of a square image (n x n, specifically 25 X 25), in $\Theta(n^2)$ time.
		
	\section{Algorithm Description}
		\paragraph{Step 1}
		Read in the image matrix $A$.
		\paragraph{Step 2}
		Compute the arrays $V$ and $H$, where $V_i = \sum\nolimits_{j = 1}^n A_{i,j}$ and $H_j = \sum\nolimits_{i = 1}^n A_{i,j}$. Intuitively, each element of $V$ is the sum of all the elements in the corresponding row of $A$, and each element of $H$ is the sum of all the elements in the corresponding column of $A$.
		\paragraph{Step 3}
		Compute the arrays $V_\delta$ and $H_\delta$, where $(V_\delta)_i = |\sum\nolimits_{r = 1}^{i - 1} V_r - \sum\nolimits_{r = i + 1}^{n} V_r|$ and $(H_\delta)_i = |\sum\nolimits_{r = 1}^{i - 1} H_r - \sum\nolimits_{r = i + 1}^{n} H_r|$. Intuitively, for each index $i$, we partition $V$ into two: one partition with element indices less than $i$ and another partition with element indices greater than $i$. We then separately sum up the elements in each partition and take the absolute value of the difference of the two sums. This difference is stored in $(V_\delta)_i.$ We do the same for each column $j$, partitioning $H$ and storing the absolute difference in sums in $(H_\delta)_j$.
		
		\paragraph{Step 4}
		Define a function $greatestMinimalIndex: S \to \mathbb{Z}^+$ that takes in an array $S$ of finite length and returns the greatest index $i$ for which $S_i$ is a minimal element of $S$. Compute $r = greatestMinimalIndex(V_\delta)$ and $c = greatestMinimalIndex(H_\delta)$.
		
		\paragraph{Step 5}
		Output $(r,c)$ as the coordinates of the centre of mass of $A$, and $A_{r,c}$ as the value of the centre of mass of $A$.
			
	
	\section{Correctness Proof}
		\paragraph{}
		Consider the output $(r,c)$ for the coordinates of the centre of mass. 
		
		\paragraph{Condition $\alpha$}
		We observe that $(V_\delta)_r$ is minimal. Thus, in the original image matrix $A$, the absolute difference between the sum of the rows above row $r$ and the sum of the rows below row $r$ is minimal.
		
		\paragraph{Condition $\beta$}
		Likewise, we observe that $(H_\delta)_c$ is minimal. This, in the original image matrix $A$, the absolute difference between the sum of the columns left of $c$ and the sum of the columns right of $c$ is minimal.
		
		\paragraph{}
		At this point, we have shown that $(r,c)$ satisfies conditions $\alpha$ and $\beta$ as denoted above. We now note that satisfying both conditions $\alpha$ and $\beta$ taken together is equivalent to satisfying the centre of mass property.
		
		\paragraph{}
		Therefore, we have shown that the coordinates $(r,c)$ output by the algorithm with image matrix $A$ indeed identify the centre of mass of the image represented by $A$.
		
		\paragraph{QED}
	
	\section{Complexity Analysis}
		\paragraph{}
		We assert in the title that the presented algorithm for computing the centre of mass of an image runs in $\Theta(n^2)$. We prove our assertion in this section.
		
		\paragraph{}
		We observe that \textbf{Step 1} involves reading in an $n x n$ matrix. This entails reading and storing $n^2$ values, and thus takes $\Theta(n^2)$ time.
		
		\paragraph{}
		Computing $V_i$ for each row $i$ involves a sum of $n$ elements, and thus each takes $\Theta(n)$ time. As computing $V$ involves computing $V_i$ for $n$ different values of $i$ (since there are $n$ rows), computing $V$ takes $\Theta(n^2)$ time. By a similar argument, computing $H$ takes $\Theta(n^2)$ time. \textbf{Step 2} thus takes $\Theta(n^2)$ time.
		
		\paragraph{}
		Computing $(V_\delta)_i$ involves $n - 1$ sums, a single subtraction and a single absolute value operation, which takes a total of $\Theta(n)$ time. Thus, computing $V_\delta$ takes $\Theta(n^2)$ time. By a similar argument, computing $H_\delta$ takes $\Theta(n^2)$ time. Thus, \textbf{Step 3} takes $\Theta(n^2)$ time.
		
		\paragraph{}
		\textbf{Step 4} involves finding the minimal element of highest index in $V_\delta$ and in $H_\delta$. Each of these only requires a single pass over the array and thus takes $\Theta(n)$ time. Thus, \textbf{Step 4} takes $\Theta(n)$ time.
		
		\paragraph{}
		\textbf{Step 5} takes $\Theta(1)$ time as it involves merely outputting 3 numbers.
	
	
\end{document}
